<!DOCTYPE HTML>
<!--
  Based on
	Spatial by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117339330-4"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117339330-4');
    </script>

    <title>
      Network Fusion for Content Creation with Conditional INNs
    </title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="landing">

		<!-- Banner -->
			<section id="banner">
        <h2>
          Network Fusion for Content Creation <br/>with Conditional INNs
        </h2>
        <p>
        <a href="https://github.com/rromb">Robin Rombach</a>&ast;,
        <a href="https://github.com/pesser">Patrick Esser</a>&ast;, 
        <a href="https://hci.iwr.uni-heidelberg.de/Staff/bommer">Bj&ouml;rn Ommer</a><br/>
        <a href="https://www.iwr.uni-heidelberg.de/">IWR, Heidelberg University</a><br/>
        <a href="http://visual.cs.brown.edu/aicc2020/">AI for Content Creation
          Workshop</a> at <a href="http://cvpr2020.thecvf.com/">CVPR 2020</a></p>
			</section>

			<!-- One -->
				<section id="one" class="wrapper style1">
					<div class="container 75%">
						<div class="row 200%">
							<div class="6u 12u$(medium) vert-center" style="margin:1% 0">
                  <div class="container 25%">

                    <div class="image fit captioned align-left"
                                style="margin-bottom:2em; box-shadow:0 0;
                                text-align:justify">
                      <img src="images/teaser.png" alt="" style="border:0px solid black"/>
                      We learn a conditional invertible neural network (cINN) to
                      translate between representations of different domain
                      experts. This results in a fused model, which can be
                      controlled through the first expert to create novel and
                      diverse content in the domain of the second expert.
                    </div>

                    <div class="image fit captioned align-center"
                                style="margin-bottom:0em; box-shadow:0 0">
                      <a href="images/netfusion.pdf">
                        <img src="images/paper.jpg" alt="" style="border:1px solid black"/>
                      </a>
                      <a href="https://arxiv.org/">arXiv</a>
                      <div class="headerDivider"></div>
                      <a href="images/netfusion.bib">BibTeX</a>
                      <br/>
                      &ast; equal contribution
                    </div>

                  </div>
							</div>
							<div class="6u$ 12u$(medium)">
                <h1>Abstract</h1>
                <p style="text-align: justify">
Artificial Intelligence for Content Creation has the potential to reduce the
amount of manual content creation work significantly. While automation of
laborious work is welcome, it is only useful if it allows users to control
aspects of the creative process when desired. Furthermore, widespread adoption
of semi-automatic content creation depends on low barriers regarding the
expertise, computational budget and time required to obtain results and
experiment with new techniques.  With state-of-the-art approaches relying on
task-specific models, multi-GPU setups and weeks of training time, we must find
ways to reuse and recombine them to meet these requirements. Instead of
designing and training methods for controllable content creation from scratch,
we thus present a method to repurpose powerful, existing models for new tasks,
even though they have never been designed for them.  We formulate this problem
as a translation between expert models, which includes common content creation
scenarios, such as text-to-image and image-to-image translation, as a special
case. As this translation is ambiguous, we learn a generative model of hidden
representations of one expert conditioned on hidden representations of the
other expert. Working on the level of hidden representations makes optimal use
of the computational effort that went into the training of the expert model to
produce these efficient, low-dimensional representations. Experiments
demonstrate that our approach can translate from BERT, a state-of-the-art
expert for text, to BigGAN, a state-of-the-art expert for images, to enable
text-to-image generation, which neither of the experts can perform on its own.
Additional experiments show the wide applicability of our approach across
different conditional image synthesis tasks and improvements over existing
methods for image modifications.
                </p>
							</div>
						</div>
					</div>
				</section>

			<!-- Two -->
				<section id="two" class="wrapper style2 special">
					<div class="container">
						<header class="major">
							<h2>Results</h2>
							<p>and applications of our model.</p>
						</header>

            __TEMPLATE_STRING__

				  </div>
				</section>


			<!-- Four -->
				<section id="four" class="wrapper style3 special">
					<div class="container">
						<header class="major">
							<h2>Acknowledgement</h2>
              <p>
              This page is based on a design by <a href="http://templated.co">TEMPLATED</a>.
              </p>
						</header>
					</div>
				</section>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
